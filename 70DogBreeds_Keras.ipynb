{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObpmR3NrAAcr1IinKCtOy4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beanbean0510/AWINLAB_homework/blob/main/70DogBreeds_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**深度學習（Deep Learning）**\n",
        "- **資料集：**70 Dog Breeds-Image Data Set（https://www.kaggle.com/datasets/gpiosenka/70-dog-breedsimage-data-set）\n",
        "- **指定類別：**\"Airedale\", \"Beagle\", \"Bloodhound\", \"Bluetick\", \"Chihuahua\", \"Collie\", \"Dingo\", \" French Bulldog\", \" German Sheperd\", \" Malinois\", \" Newfoundland\", \" Pekinese\", \" Pomeranian\", \"Pug\", \"Vizsla\" 共15項\n",
        "- **使用環境：**Google CoLab\n"
      ],
      "metadata": {
        "id": "mBIng9ukW2Zk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**首先連結 Google Drive 檔案**"
      ],
      "metadata": {
        "id": "wgr1N15ia-M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 將檔案連接至 Google Drive 雲端硬碟 ###\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-X0CoVqbK5o",
        "outputId": "2dd2aa11-173a-4e3e-e6c5-cee2c17cef43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 檢視雲端硬碟中的檔案路徑 確認檔案所在地 ###\n",
        "from pathlib import Path\n",
        "\n",
        "# 將所有在路徑 '/content/drive/MyDrive/AWINLAB/' 中的檔案印出，確認所需資料是否存在\n",
        "for path in Path('/content/drive/MyDrive/AWINLAB/').glob(\"*\"):\n",
        "  print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNr0NMjtbZV0",
        "outputId": "3c9e9f5a-b7b9-4208-c5f5-ec9ef0d44b1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AWINLAB/dogs.csv\n",
            "/content/drive/MyDrive/AWINLAB/test_data.xlsx\n",
            "/content/drive/MyDrive/AWINLAB/valid\n",
            "/content/drive/MyDrive/AWINLAB/train\n",
            "/content/drive/MyDrive/AWINLAB/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **函式庫筆記**\n",
        "1. ***numpy***：\n",
        "  - 提供非常高效能的多維陣列(multi-dimensional array)數學函式庫\n",
        "  - 可整合C/C++及Fortran的程式碼\n",
        "  - 方便有用的線性代數(Linear Algebra)及傅立葉轉換(Fourier Transform)能力\n",
        "  - 利用NumPy Array替代Python List\n",
        "  - 可定義任意的數據型態(Data Type)，使得能輕易及無縫的與多種資料庫整合\n",
        "2. ***matplotlib***\n",
        "  - 為 python 的一個 2D 繪圖庫\n",
        "  - 可用來繪圖、呈現圖表、表示數據\n",
        "3. ***pandas***\n",
        "  - 可以被用來執行強大的資料分析\n",
        "  - 結合 numpy 的特性以及試算表和關連式資料庫的資料操作能力，可以用來對資料進行重構、切割、聚合及選擇子集合等操作\n",
        "4. ***tensorflow***\n",
        "  - 是一個免費的開源軟體程式庫，適用於機器學習和人工智慧\n",
        "5. ***keras***\n",
        "  - 是一個深度學習的開源函式庫\n",
        "  - 能夠提供簡單而快速的原型設計，是個高度模組化的函式庫，可以讓用戶快速的去建造神經網路並訓練模型"
      ],
      "metadata": {
        "id": "QIli0cG8T-pB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q1hVy7dlWpcW"
      },
      "outputs": [],
      "source": [
        "### 導入所需的函式庫 ###\n",
        "# 常用函式庫\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 機器學習、深度學習相關\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 導入 Sequential 用來搭建線性堆疊模型\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# 導入 keras 的層（layers）中所需的各種工具\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout , Input , BatchNormalization\n",
        "\n",
        "# 導入 keras 的優化器（optimizers）中所需的各種工具\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 引入所需資料 ###\n",
        "df_train = '/content/drive/MyDrive/AWINLAB/train'\n",
        "df_valid = '/content/drive/MyDrive/AWINLAB/valid'\n",
        "df_test = '/content/drive/MyDrive/AWINLAB/test'"
      ],
      "metadata": {
        "id": "IoUYXPZGcp2c"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ***ImageDataGenerator：***可利用現有的資料經過旋轉、翻轉、縮放…等方式增加更多的訓練資料"
      ],
      "metadata": {
        "id": "Tp5zqRuoiUeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 將圖像的像素縮放到指定的範圍內，一般會縮放至[0,1]之間\n",
        "datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "8jTomLRGdifc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 調整資料，將資料批次（batch）設為64、並將圖像像素（target）調整成224x224、分類標籤設為'categorical'利用one-hot轉換\n",
        "ds_train = datagen.flow_from_directory(df_train, batch_size = 64, target_size = (224, 224),\n",
        "                                       class_mode = 'categorical')\n",
        "\n",
        "ds_valid = datagen.flow_from_directory(df_valid, batch_size = 64, target_size = (224, 224),\n",
        "                                       class_mode = 'categorical')\n",
        "\n",
        "ds_test = datagen.flow_from_directory(df_test, batch_size = 64, target_size = (224, 224),\n",
        "                                       class_mode = 'categorical')\n",
        "\n",
        "# 因為資料共有15個類別，故設為15\n",
        "num_classes = 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koRF79HRdrhD",
        "outputId": "816e61eb-cb67-4172-982c-55f10e1e3fed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1714 images belonging to 15 classes.\n",
            "Found 150 images belonging to 15 classes.\n",
            "Found 300 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 建立 CNN 模型 ###\n",
        "\n",
        "# 指定圖像的尺寸和維度\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# 建立一個線性堆疊的模型，用於按順序堆疊神經網路層\n",
        "model = Sequential()\n",
        "# 增加輸入層，設定輸入格式為剛剛設定的 input_shape\n",
        "model.add(Input(shape=input_shape))\n",
        "# 加入第一層卷積層，過濾器大小設為3x3數量為32個，激勵函數設為'ReLU'\n",
        "# ReLU 線性整流單元：會將所有負值轉換成零，避免卷積的過程將數字變成無限大或是趨近於0\n",
        "將所有負值轉換成零，可以避免卷積的過程將數字變成無限大或是趨近於0\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# 加入池化層：保留重要資訊，減少參數數量\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# 加入批歸一化層：可將分散的數據統一，有助於減緩梯度消失，也可解決 Internal Covariate Shift 的問題及加速收斂\n",
        "model.add(BatchNormalization())\n",
        "# 重複添加上述結構，共三層\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "# 建立平坦層：將矩陣打平成一維的陣列作為輸入\n",
        "model.add(Flatten())\n",
        "# 建立隱藏層\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# 防止 overfitting\n",
        "model.add(Dropout(0.5))\n",
        "# 建立輸出層：將輸入值轉化成各個類別的機率，機率最大的即是最有可能的類別\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "# 編譯模型\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=RMSprop(),\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ks8PtndwiWM1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 訓練模型 ###\n",
        "# 訓練回數設為30回、每個批次樣本數為32\n",
        "# verbose：設為0：執行過程中不輸出資訊；設為1：顯示訓練進度訊息；設為2：為每個 epoch 輸出一行紀錄（默認為1）\n",
        "history = model.fit(ds_train, epochs = 30, validation_data = ds_valid , batch_size = 32 , verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6IVINjlki27",
        "outputId": "11ab4c39-a47c-43e8-caaa-9b0fbd097d42"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "27/27 [==============================] - 473s 17s/step - loss: 6.5383 - accuracy: 0.1820 - val_loss: 3.2297 - val_accuracy: 0.0667\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 2.3733 - accuracy: 0.4726 - val_loss: 4.3080 - val_accuracy: 0.0667\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 135s 5s/step - loss: 1.6095 - accuracy: 0.5928 - val_loss: 6.5609 - val_accuracy: 0.0800\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 1.1285 - accuracy: 0.6902 - val_loss: 4.5176 - val_accuracy: 0.1133\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 133s 5s/step - loss: 0.9609 - accuracy: 0.7357 - val_loss: 7.0663 - val_accuracy: 0.0667\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 133s 5s/step - loss: 0.7104 - accuracy: 0.8098 - val_loss: 6.4222 - val_accuracy: 0.0667\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 133s 5s/step - loss: 0.5784 - accuracy: 0.8355 - val_loss: 10.6067 - val_accuracy: 0.0733\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 133s 5s/step - loss: 0.5355 - accuracy: 0.8436 - val_loss: 8.2461 - val_accuracy: 0.0867\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 133s 5s/step - loss: 0.4633 - accuracy: 0.8757 - val_loss: 13.7260 - val_accuracy: 0.0667\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.4115 - accuracy: 0.8769 - val_loss: 12.1748 - val_accuracy: 0.1000\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.3555 - accuracy: 0.9008 - val_loss: 9.3403 - val_accuracy: 0.1067\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 133s 5s/step - loss: 0.3662 - accuracy: 0.9002 - val_loss: 11.0056 - val_accuracy: 0.1400\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.3577 - accuracy: 0.8985 - val_loss: 11.4940 - val_accuracy: 0.1000\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.3493 - accuracy: 0.9020 - val_loss: 17.2682 - val_accuracy: 0.0800\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 133s 5s/step - loss: 0.2807 - accuracy: 0.9177 - val_loss: 7.6043 - val_accuracy: 0.1867\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.2929 - accuracy: 0.9224 - val_loss: 9.1752 - val_accuracy: 0.2067\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 135s 5s/step - loss: 0.2331 - accuracy: 0.9282 - val_loss: 9.3091 - val_accuracy: 0.1600\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.2650 - accuracy: 0.9294 - val_loss: 6.2205 - val_accuracy: 0.3267\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.2255 - accuracy: 0.9312 - val_loss: 5.8609 - val_accuracy: 0.2667\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.2833 - accuracy: 0.9212 - val_loss: 6.6176 - val_accuracy: 0.1800\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 133s 5s/step - loss: 0.2012 - accuracy: 0.9469 - val_loss: 4.3582 - val_accuracy: 0.3533\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 144s 5s/step - loss: 0.1711 - accuracy: 0.9446 - val_loss: 4.2878 - val_accuracy: 0.3600\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.1659 - accuracy: 0.9498 - val_loss: 3.6199 - val_accuracy: 0.4000\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.2136 - accuracy: 0.9475 - val_loss: 4.5403 - val_accuracy: 0.3733\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.1593 - accuracy: 0.9487 - val_loss: 4.4965 - val_accuracy: 0.3800\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 144s 5s/step - loss: 0.1785 - accuracy: 0.9522 - val_loss: 2.4005 - val_accuracy: 0.3933\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.1607 - accuracy: 0.9498 - val_loss: 2.9384 - val_accuracy: 0.4067\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 134s 5s/step - loss: 0.1957 - accuracy: 0.9510 - val_loss: 2.8933 - val_accuracy: 0.4133\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 136s 5s/step - loss: 0.1569 - accuracy: 0.9551 - val_loss: 2.5147 - val_accuracy: 0.4200\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 139s 5s/step - loss: 0.1688 - accuracy: 0.9527 - val_loss: 3.7802 - val_accuracy: 0.3667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 利用 Testing set 評估模型 ###\n",
        "loss_cnn, accuracy_cnn = model.evaluate(ds_test)\n",
        "loss_cnn = loss_cnn*100\n",
        "accuracy_cnn = accuracy_cnn*100\n",
        "print('Test loss:', loss_cnn)\n",
        "print('Test accuracy:', accuracy_cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSve2DNl20or",
        "outputId": "1478a46e-b496-4bbc-ff98-50acb9c74e54"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 47s 11s/step - loss: 229.1060 - accuracy: 0.0767\n",
            "Test loss: 22910.604858398438\n",
            "Test accuracy: 7.666666805744171\n"
          ]
        }
      ]
    }
  ]
}